{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":658267,"sourceType":"datasetVersion","datasetId":277323}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:04:46.061249Z","iopub.execute_input":"2025-03-25T18:04:46.061697Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nprint(os.listdir(\"/kaggle/input/\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:38:02.799701Z","iopub.execute_input":"2025-03-25T18:38:02.799995Z","iopub.status.idle":"2025-03-25T18:38:02.804867Z","shell.execute_reply.started":"2025-03-25T18:38:02.799973Z","shell.execute_reply":"2025-03-25T18:38:02.803949Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(os.listdir(\"/kaggle/input/plantvillage-dataset/\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:38:07.025538Z","iopub.execute_input":"2025-03-25T18:38:07.025813Z","iopub.status.idle":"2025-03-25T18:38:07.039362Z","shell.execute_reply.started":"2025-03-25T18:38:07.025791Z","shell.execute_reply":"2025-03-25T18:38:07.038605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(os.listdir(\"/kaggle/input/plantvillage-dataset/color/\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:38:09.816280Z","iopub.execute_input":"2025-03-25T18:38:09.816607Z","iopub.status.idle":"2025-03-25T18:38:09.824191Z","shell.execute_reply.started":"2025-03-25T18:38:09.816583Z","shell.execute_reply":"2025-03-25T18:38:09.823492Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\n# each time the neural networks trains, in randomly generates is parameter values # to avoid different outputs each time\n\nrandom.seed(0)\nimport numpy as np\nnp.random.seed(0)\n\nimport tensorflow as tf\ntf.random.set_seed(0)\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:38:14.270405Z","iopub.execute_input":"2025-03-25T18:38:14.270698Z","iopub.status.idle":"2025-03-25T18:38:26.089089Z","shell.execute_reply.started":"2025-03-25T18:38:14.270676Z","shell.execute_reply":"2025-03-25T18:38:26.088437Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nfrom zipfile import ZipFile\nfrom PIL import Image\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:38:31.721173Z","iopub.execute_input":"2025-03-25T18:38:31.721760Z","iopub.status.idle":"2025-03-25T18:38:31.727053Z","shell.execute_reply.started":"2025-03-25T18:38:31.721729Z","shell.execute_reply":"2025-03-25T18:38:31.726195Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:39:05.008436Z","iopub.execute_input":"2025-03-25T18:39:05.008760Z","iopub.status.idle":"2025-03-25T18:39:05.137600Z","shell.execute_reply.started":"2025-03-25T18:39:05.008735Z","shell.execute_reply":"2025-03-25T18:39:05.136496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Correct dataset path\ndataset_path = \"/kaggle/input/plantvillage-dataset/\"\n\n# Print available folders in the dataset\nprint(os.listdir(dataset_path))\n\n# Print the number of classes and first 5 classes for each dataset version\nprint(len(os.listdir(dataset_path + \"segmented\")))\nprint(os.listdir(dataset_path + \"segmented\")[:5])\n\nprint(len(os.listdir(dataset_path + \"color\")))\nprint(os.listdir(dataset_path + \"color\")[:5])\n\nprint(len(os.listdir(dataset_path + \"grayscale\")))\nprint(os.listdir(dataset_path + \"grayscale\")[:5])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:39:06.506736Z","iopub.execute_input":"2025-03-25T18:39:06.507031Z","iopub.status.idle":"2025-03-25T18:39:06.610055Z","shell.execute_reply.started":"2025-03-25T18:39:06.507006Z","shell.execute_reply":"2025-03-25T18:39:06.609419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Correct dataset path\ndataset_path = \"/kaggle/input/plantvillage-dataset/\"\n\n# Check the number of images in the \"Grape___healthy\" class inside the \"color\" dataset\ngrape_healthy_path = dataset_path + \"color/Grape___healthy\"\nprint(len(os.listdir(grape_healthy_path)))  # Print total image count\n\n# Print first 5 image filenames\nprint(os.listdir(grape_healthy_path)[:5])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:39:12.985430Z","iopub.execute_input":"2025-03-25T18:39:12.985716Z","iopub.status.idle":"2025-03-25T18:39:13.134732Z","shell.execute_reply.started":"2025-03-25T18:39:12.985687Z","shell.execute_reply":"2025-03-25T18:39:13.133998Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_dir = \"/kaggle/input/plantvillage-dataset/color\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:39:14.152401Z","iopub.execute_input":"2025-03-25T18:39:14.152682Z","iopub.status.idle":"2025-03-25T18:39:14.156363Z","shell.execute_reply.started":"2025-03-25T18:39:14.152660Z","shell.execute_reply":"2025-03-25T18:39:14.155554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport os\n\n# Correct dataset path\ndataset_path = \"/kaggle/input/plantvillage-dataset/color/Apple___Cedar_apple_rust/\"\n\n# Pick a random image from the class folder\nrandom_image = os.listdir(dataset_path)[0]  # First image\nimage_path = os.path.join(dataset_path, random_image)\n\n# Load and display the image\nimg = mpimg.imread(image_path)\n\nprint(\"Image shape:\", img.shape)  # Print image dimensions\n\nplt.imshow(img)\nplt.axis('off')  # Hide axes\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:39:15.683074Z","iopub.execute_input":"2025-03-25T18:39:15.683373Z","iopub.status.idle":"2025-03-25T18:39:16.024219Z","shell.execute_reply.started":"2025-03-25T18:39:15.683315Z","shell.execute_reply":"2025-03-25T18:39:16.023445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.image as mpimg\nimport os\n\n# Correct dataset path\ndataset_path = \"/kaggle/input/plantvillage-dataset/color/Apple___Cedar_apple_rust/\"\n\n# Pick a random image from the folder\nrandom_image = os.listdir(dataset_path)[0]  # Select first image\nimage_path = os.path.join(dataset_path, random_image)\n\n# Load image as NumPy array\nimg = mpimg.imread(image_path)\nprint(\"Image shape:\", img.shape)  # Print image dimensions\nprint(img)  # Print pixel values\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:39:23.184504Z","iopub.execute_input":"2025-03-25T18:39:23.184794Z","iopub.status.idle":"2025-03-25T18:39:23.214103Z","shell.execute_reply.started":"2025-03-25T18:39:23.184773Z","shell.execute_reply":"2025-03-25T18:39:23.213426Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Setting a uniform height and width to all images\nimg_size = 224\nbatch_size = 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:39:24.574119Z","iopub.execute_input":"2025-03-25T18:39:24.574447Z","iopub.status.idle":"2025-03-25T18:39:24.577959Z","shell.execute_reply.started":"2025-03-25T18:39:24.574418Z","shell.execute_reply":"2025-03-25T18:39:24.577020Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_gen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2 # 20% of data for validation\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:39:29.330482Z","iopub.execute_input":"2025-03-25T18:39:29.330880Z","iopub.status.idle":"2025-03-25T18:39:29.335428Z","shell.execute_reply.started":"2025-03-25T18:39:29.330847Z","shell.execute_reply":"2025-03-25T18:39:29.334349Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train generator\ntrain_generator = data_gen.flow_from_directory(\n    base_dir,\n    target_size=(img_size, img_size),\n    batch_size=batch_size,\n    subset='training',\n    class_mode='categorical'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:39:31.278901Z","iopub.execute_input":"2025-03-25T18:39:31.279239Z","iopub.status.idle":"2025-03-25T18:40:04.309149Z","shell.execute_reply.started":"2025-03-25T18:39:31.279209Z","shell.execute_reply":"2025-03-25T18:40:04.308275Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# validation generator\nvalidation_generator = data_gen.flow_from_directory(\n    base_dir,\n    target_size=(img_size, img_size),\n    batch_size=batch_size,\n    subset='validation',\n    class_mode='categorical'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:40:04.310244Z","iopub.execute_input":"2025-03-25T18:40:04.310563Z","iopub.status.idle":"2025-03-25T18:40:15.911831Z","shell.execute_reply.started":"2025-03-25T18:40:04.310536Z","shell.execute_reply":"2025-03-25T18:40:15.911164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras import models, layers, optimizers, Input\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nmodel = models.Sequential([\n    Input(shape=(img_size, img_size, 3)),  # ‚úÖ Define input explicitly\n\n    layers.Conv2D(32, (3, 3), padding='same'),\n    layers.BatchNormalization(),  # ‚úÖ Move BN before ReLU\n    layers.Activation('relu'),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Conv2D(64, (3, 3), padding='same'),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Conv2D(128, (3, 3), padding='same'),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Conv2D(256, (3, 3), padding='same'),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Conv2D(512, (3, 3), padding='same'),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.GlobalAveragePooling2D(),\n\n    layers.Dense(512),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.Dropout(0.4),  # üî∫ Slightly reduce dropout\n\n    layers.Dense(256),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.Dropout(0.3),\n\n    layers.Dense(train_generator.num_classes, activation='softmax')  # ‚úÖ Output Layer\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:58:59.121766Z","iopub.execute_input":"2025-03-25T18:58:59.122076Z","iopub.status.idle":"2025-03-25T18:58:59.245727Z","shell.execute_reply.started":"2025-03-25T18:58:59.122055Z","shell.execute_reply":"2025-03-25T18:58:59.245059Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T18:59:02.669888Z","iopub.execute_input":"2025-03-25T18:59:02.670181Z","iopub.status.idle":"2025-03-25T18:59:02.701919Z","shell.execute_reply.started":"2025-03-25T18:59:02.670158Z","shell.execute_reply":"2025-03-25T18:59:02.701285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(\n    optimizer=optimizers.Adam(learning_rate=0.0001),  # Lower learning rate\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:14:27.511860Z","iopub.execute_input":"2025-03-25T19:14:27.512154Z","iopub.status.idle":"2025-03-25T19:14:27.525294Z","shell.execute_reply.started":"2025-03-25T19:14:27.512130Z","shell.execute_reply":"2025-03-25T19:14:27.524641Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:15:33.208996Z","iopub.execute_input":"2025-03-25T19:15:33.209276Z","iopub.status.idle":"2025-03-25T19:15:33.213004Z","shell.execute_reply.started":"2025-03-25T19:15:33.209254Z","shell.execute_reply":"2025-03-25T19:15:33.212081Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import math\n\nsteps_per_epoch = max(1, train_generator.samples // batch_size)\nvalidation_steps = max(1, validation_generator.samples // batch_size)\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=steps_per_epoch,\n    epochs=50,\n    validation_data=validation_generator,\n    validation_steps=validation_steps,\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T19:31:29.015830Z","iopub.execute_input":"2025-03-25T19:31:29.016118Z","iopub.status.idle":"2025-03-25T20:18:00.074280Z","shell.execute_reply.started":"2025-03-25T19:31:29.016098Z","shell.execute_reply":"2025-03-25T20:18:00.073404Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check best epoch\n# Find the epoch with the best validation accuracy\nbest_epoch = np.argmax(history.history['val_accuracy']) + 1  # Adding 1 because epoch index starts from 0\n\nprint(f\"Best epoch: {best_epoch}\")\nprint(f\"Best Validation Accuracy: {max(history.history['val_accuracy'])}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T20:19:35.950498Z","iopub.execute_input":"2025-03-25T20:19:35.950822Z","iopub.status.idle":"2025-03-25T20:19:35.955945Z","shell.execute_reply.started":"2025-03-25T20:19:35.950795Z","shell.execute_reply":"2025-03-25T20:19:35.954972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epoch_46_index = 45  # Since epochs are 0-indexed in history\n\ntrain_accuracy_46 = history.history['accuracy'][epoch_46_index] * 100\nval_accuracy_46 = history.history['val_accuracy'][epoch_46_index] * 100\n\nprint(f\"Train Accuracy at Epoch 46: {train_accuracy_46:.2f}%\")\nprint(f\"Validation Accuracy at Epoch 46: {val_accuracy_46:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T20:50:27.525207Z","iopub.execute_input":"2025-03-25T20:50:27.525530Z","iopub.status.idle":"2025-03-25T20:50:27.530745Z","shell.execute_reply.started":"2025-03-25T20:50:27.525500Z","shell.execute_reply":"2025-03-25T20:50:27.529745Z"}},"outputs":[{"name":"stdout","text":"Train Accuracy at Epoch 46: 0.00%\nValidation Accuracy at Epoch 46: 100.00%\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"best_epoch_loss = np.argmin(history.history['val_loss']) + 1\n\nprint(f\"Best epoch (lowest loss): {best_epoch_loss}\")\nprint(f\"Lowest Validation Loss: {min(history.history['val_loss'])}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T20:50:18.526060Z","iopub.execute_input":"2025-03-25T20:50:18.526370Z","iopub.status.idle":"2025-03-25T20:50:18.531031Z","shell.execute_reply.started":"2025-03-25T20:50:18.526324Z","shell.execute_reply":"2025-03-25T20:50:18.530027Z"}},"outputs":[{"name":"stdout","text":"Best epoch (lowest loss): 46\nLowest Validation Loss: 2.7418097943154862e-06\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"print(\"Evaluating model...\")\nval_loss, val_accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)\nprint(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T20:49:37.700838Z","iopub.execute_input":"2025-03-25T20:49:37.701114Z","iopub.status.idle":"2025-03-25T20:50:08.424692Z","shell.execute_reply.started":"2025-03-25T20:49:37.701091Z","shell.execute_reply":"2025-03-25T20:50:08.423944Z"}},"outputs":[{"name":"stdout","text":"Evaluating model...\n\u001b[1m339/339\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 90ms/step - accuracy: 0.9179 - loss: 0.2769\nValidation Accuracy: 92.26%\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n%matplotlib inline  \n\nplt.figure(figsize=(8, 5))\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(loc='upper left')\nplt.grid()\nplt.show()\n\nplt.figure(figsize=(8, 5))\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(loc='upper left')\nplt.grid()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T20:26:57.415970Z","iopub.execute_input":"2025-03-25T20:26:57.416185Z","iopub.status.idle":"2025-03-25T20:26:57.799324Z","shell.execute_reply.started":"2025-03-25T20:26:57.416164Z","shell.execute_reply":"2025-03-25T20:26:57.798474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\n\n# Function to Load and Preprocess the Image using Pillow\ndef load_and_preprocess_image(image_path, target_size=(224, 224)):\n    try:\n        # Load the image and ensure it's in RGB mode\n        img = Image.open(image_path).convert('RGB')\n        # Resize the image\n        img = img.resize(target_size)\n        # Convert the image to a numpy array\n        img_array = np.array(img)\n        # Add batch dimension\n        img_array = np.expand_dims(img_array, axis=0)\n        # Normalize pixel values to [0, 1]\n        img_array = img_array.astype('float32') / 255.0\n        return img_array\n    except Exception as e:\n        print(f\"Error loading image: {e}\")\n        return None\n\n# Function to Predict the Class of an Image\ndef predict_image_class(model, image_path, train_generator):\n    preprocessed_img = load_and_preprocess_image(image_path)\n    if preprocessed_img is None:\n        return \"Error: Unable to process image.\"\n\n    predictions = model.predict(preprocessed_img)\n    predicted_class_index = np.argmax(predictions, axis=1)[0]\n    \n    # Get class labels (Invert train_generator.class_indices)\n    class_indices = {v: k for k, v in train_generator.class_indices.items()}\n    predicted_class_name = class_indices.get(predicted_class_index, \"Unknown Class\")\n\n    return predicted_class_name\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T20:27:13.170910Z","iopub.execute_input":"2025-03-25T20:27:13.171266Z","iopub.status.idle":"2025-03-25T20:27:13.177426Z","shell.execute_reply.started":"2025-03-25T20:27:13.171237Z","shell.execute_reply":"2025-03-25T20:27:13.176568Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a mapping from class indices to class names\nclass_indices = {v: k for k, v in train_generator.class_indices.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T20:49:30.224950Z","iopub.execute_input":"2025-03-25T20:49:30.225223Z","iopub.status.idle":"2025-03-25T20:49:30.228800Z","shell.execute_reply.started":"2025-03-25T20:49:30.225202Z","shell.execute_reply":"2025-03-25T20:49:30.227938Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"class_indices","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T20:49:27.464175Z","iopub.execute_input":"2025-03-25T20:49:27.464478Z","iopub.status.idle":"2025-03-25T20:49:27.470141Z","shell.execute_reply.started":"2025-03-25T20:49:27.464455Z","shell.execute_reply":"2025-03-25T20:49:27.469351Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"{0: 'Apple___Apple_scab',\n 1: 'Apple___Black_rot',\n 2: 'Apple___Cedar_apple_rust',\n 3: 'Apple___healthy',\n 4: 'Blueberry___healthy',\n 5: 'Cherry_(including_sour)___Powdery_mildew',\n 6: 'Cherry_(including_sour)___healthy',\n 7: 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',\n 8: 'Corn_(maize)___Common_rust_',\n 9: 'Corn_(maize)___Northern_Leaf_Blight',\n 10: 'Corn_(maize)___healthy',\n 11: 'Grape___Black_rot',\n 12: 'Grape___Esca_(Black_Measles)',\n 13: 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',\n 14: 'Grape___healthy',\n 15: 'Orange___Haunglongbing_(Citrus_greening)',\n 16: 'Peach___Bacterial_spot',\n 17: 'Peach___healthy',\n 18: 'Pepper,_bell___Bacterial_spot',\n 19: 'Pepper,_bell___healthy',\n 20: 'Potato___Early_blight',\n 21: 'Potato___Late_blight',\n 22: 'Potato___healthy',\n 23: 'Raspberry___healthy',\n 24: 'Soybean___healthy',\n 25: 'Squash___Powdery_mildew',\n 26: 'Strawberry___Leaf_scorch',\n 27: 'Strawberry___healthy',\n 28: 'Tomato___Bacterial_spot',\n 29: 'Tomato___Early_blight',\n 30: 'Tomato___Late_blight',\n 31: 'Tomato___Leaf_Mold',\n 32: 'Tomato___Septoria_leaf_spot',\n 33: 'Tomato___Spider_mites Two-spotted_spider_mite',\n 34: 'Tomato___Target_Spot',\n 35: 'Tomato___Tomato_Yellow_Leaf_Curl_Virus',\n 36: 'Tomato___Tomato_mosaic_virus',\n 37: 'Tomato___healthy'}"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"# saving the class names as json file\njson.dump(class_indices, open('class_indices.json', 'w'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T20:34:49.242920Z","iopub.execute_input":"2025-03-25T20:34:49.243254Z","iopub.status.idle":"2025-03-25T20:34:49.247384Z","shell.execute_reply.started":"2025-03-25T20:34:49.243225Z","shell.execute_reply":"2025-03-25T20:34:49.246710Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"my_trained_model.h5\")  # Saving the entire model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T20:51:22.848478Z","iopub.execute_input":"2025-03-25T20:51:22.848759Z","iopub.status.idle":"2025-03-25T20:51:22.978634Z","shell.execute_reply.started":"2025-03-25T20:51:22.848738Z","shell.execute_reply":"2025-03-25T20:51:22.977620Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nmodel = load_model(\"my_trained_model.h5\")\n\n# On reopening Kaggle I just need to run this cell instead of retraining","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-25T20:52:01.599165Z","iopub.execute_input":"2025-03-25T20:52:01.599512Z","iopub.status.idle":"2025-03-25T20:52:01.988983Z","shell.execute_reply.started":"2025-03-25T20:52:01.599481Z","shell.execute_reply":"2025-03-25T20:52:01.988260Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')\n\n!mv my_model.h5 /content/drive/MyDrive/","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}